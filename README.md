# ETL-Project-Data-Science-Jobs

## Team Name: Kicking Kangaroos

In this project the team scraped data from Indeed to determine the total number of data scientist job openings by companies throughout the United States. Data was also scraped from Zillow to determine housing prices in different cities where there is a high demand for data scientists.

Data was extracted into csv files, transformed (cleaned), and loaded to a database (PostgreSQL). 

### Python libraries:

* Requests
* Pandas
* BeautifulSoup
* Glob
* Splinter
* Os
* Time
* Pathlib

### Team Members Assigned Tasks: 

* Andy Kwon: responsible for scrapping Indeed to retrieve data science roles and salaries..
* Wayne Tseng: responsible for scrapping Indeed to determine which companies have the highest demands for data science roles.
* Fabiola Cartagena: responsible for scrapping Zillow to retrieve housing prices by location (cities).
* Hyun Soo Kim: responsible for creating ERD, and loading data to postgreSQL.

### Analysis

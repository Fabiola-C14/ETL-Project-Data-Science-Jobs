{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is HGST_5TB\n",
      " Volume Serial Number is 4CF5-8CDE\n",
      "\n",
      " Directory of D:\\GitHub\\USC-Data-Bootcamp\\unit_13_project2_repo\\company-info\n",
      "\n",
      "06/27/2020  12:08 PM    <DIR>          .\n",
      "06/27/2020  12:08 PM    <DIR>          ..\n",
      "06/27/2020  10:40 AM    <DIR>          .ipynb_checkpoints\n",
      "06/27/2020  12:00 PM    <DIR>          _archived\n",
      "06/27/2020  12:08 PM            27,079 scrape_company_info.ipynb\n",
      "               1 File(s)         27,079 bytes\n",
      "               4 Dir(s)  3,957,297,328,128 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = pathlib.Path(f'../csv/company_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 8, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-af14da4fb3e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompany_info_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 8, saw 3\n"
     ]
    }
   ],
   "source": [
    "company_info_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CITIES = {'New York', 'Chicago', 'San Francisco', 'Austin', 'Seattle',\n",
    "                  'Los Angeles', 'Philadelphia', 'Atlanta', 'Dallas',\n",
    "                  'Pittsburgh', 'Portland', 'Phoenix', 'Denver', 'Houston',\n",
    "                  'Miami'}\n",
    "\n",
    "YOUR_CITIES = {'Boston', 'Washington DC', 'St Louis', 'San Diego',\n",
    "               'San Antonio', 'Columbus', 'Sacramento', 'Charlotte', 'Memphis',\n",
    "               'Detroit', 'Nashville', 'Jacksonville', 'Indianapolis',\n",
    "               'Fort Worth', 'Charlotte', 'El Paso', 'Oklahoma City',\n",
    "               'Las Vegas', 'Louisville', 'Milwaukee', 'Albuquerque', 'Tucson',\n",
    "               'Kansas City', 'Mesa', 'Colorado Springs', 'Raleigh', 'Omaha',\n",
    "               'Virginia Beach', 'Minneapolis', 'New Orleans', 'Tampa',\n",
    "               'San Jose', 'Baltimore', 'Fresno', 'Oakland', 'Tulsa', 'Madison',\n",
    "               'Arlington', 'Wichita', 'Cleveland', 'Aurora', 'Honolulu',\n",
    "               'Orlando', 'Anchorage', 'Des Moines', 'Salt Lake City',\n",
    "               'Lexington', 'Cincinnati', 'Newark', 'Durham', 'Buffalo',\n",
    "               'Baton Rouge', 'Richmond', 'Boise', 'Birmingham', 'Little Rock',\n",
    "               'Grand Rapids', 'Worcester', 'Providence', 'Sioux Falls',\n",
    "               'Jackson', 'Hartford', 'Bridgeport', 'Jersey City', 'Charleston',\n",
    "               'Billings', 'Fargo', 'Augusta'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location(result):\n",
    "    \"\"\"extract job location\"\"\"\n",
    "    try:\n",
    "        location = result.find('span', class_='location').get_text().strip()\n",
    "        return location\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company(result):\n",
    "    \"\"\"extract the name of the company\"\"\"\n",
    "    try:\n",
    "        company = result.find('span', class_='company').get_text().strip()\n",
    "        return company\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title(result):\n",
    "    \"\"\"extract the job title\"\"\"\n",
    "    try:\n",
    "        title = result.find('a', attrs={'data-tn-element': \"jobTitle\"}).get(\n",
    "            'title')\n",
    "        return title\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_star(result):\n",
    "    \"\"\"extract a number (width) that is proportional to the number of stars\n",
    "    shown for the company\"\"\"\n",
    "    try:\n",
    "        # the 'style' attribute dictates how many stars are filled with color\n",
    "        star = result.find('span', class_='ratingsContent').get_text()\n",
    "        # extract only the number\n",
    "        star = star.replace('\"\"', '').replace('\\n', '')\n",
    "        return star\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.indeed.com/jobs\"\n",
    "params = {'q': 'data scientist', 'radius': '100'}\n",
    "# params = {'radius': '100'}\n",
    "max_results = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?radius=100&l=Miami&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Portland&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Austin&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Dallas&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Phoenix&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Denver&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=San+Francisco&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=New+York&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Atlanta&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Philadelphia&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Pittsburgh&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Los+Angeles&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Chicago&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Seattle&start=0\n",
      "------------------------------------------------------------------------\n",
      "https://www.indeed.com/jobs?radius=100&l=Houston&start=0\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# for city in DEFAULT_CITIES | YOUR_CITIES:\n",
    "for city in DEFAULT_CITIES:\n",
    "    for start in range(0, max_results, 10):\n",
    "        url_params = params.copy()\n",
    "        url_params.update({'l': city, 'start': start})\n",
    "        scraped_data = {'location': [],\n",
    "                    'company': [],\n",
    "                    'title': [],\n",
    "                    'star': []}\n",
    "        response = requests.get(url, params=url_params)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        results = soup.find_all('div', class_='result')\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        print(response.url)\n",
    "        print('------------------------------------------------------------------------')\n",
    "        \n",
    "        for result in results:\n",
    "            scraped_data['location'].append(extract_location(result))\n",
    "            scraped_data['company'].append(extract_company(result))\n",
    "            scraped_data['title'].append(extract_title(result))\n",
    "            scraped_data['star'].append(extract_star(result))\n",
    "            \n",
    "        company_info_df = pd.DataFrame(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>TTEC</td>\n",
       "      <td>Customer Service Representative - Work from Home</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Commercial Beverage Concepts, LLC</td>\n",
       "      <td>Warehouse Financial Analyst</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>EMPC</td>\n",
       "      <td>Quality Control Specialist</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Allstyle</td>\n",
       "      <td>Global Shop ERP Software Specialist</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>GEORGIA-PACIFIC</td>\n",
       "      <td>PLYWOOD TRAINEE</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>Houston Gateway Academy, Inc</td>\n",
       "      <td>2020 - 2021 Certified Teachers</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>Altus ACE</td>\n",
       "      <td>IT Business Analyst</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>HEB</td>\n",
       "      <td>Curbside In Store Shopper</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>HEB</td>\n",
       "      <td>Checker</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>HEB</td>\n",
       "      <td>FT Curbside Shopper</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rosenberg, TX</td>\n",
       "      <td>Frito-Lay North America</td>\n",
       "      <td>Warehouse/Material Handler</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Houston, TX 77090</td>\n",
       "      <td>NINJA Nation - Aflac</td>\n",
       "      <td>Insurance Agent - Training Provided &amp; Flexible...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sugar Land, TX</td>\n",
       "      <td>HEB</td>\n",
       "      <td>Night Stocker</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Houston, TX 77002 (Downtown area)</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>Harris County Sheriff's Office Career Opportun...</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kingwood, TX 77345 (Far Northeast area)</td>\n",
       "      <td>HEB</td>\n",
       "      <td>Night Stocker - PT</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Spring, TX</td>\n",
       "      <td>HEB</td>\n",
       "      <td>Grocery Night Stocker</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Moderno Porcelain Works</td>\n",
       "      <td>Apprentice - Houston, TX</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td>U.S. Customs and Border Protection</td>\n",
       "      <td>Border Patrol Agent</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>Federal Bureau of Investigation</td>\n",
       "      <td>Special Agent</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   location  \\\n",
       "0                                      None   \n",
       "1                                      None   \n",
       "2                                      None   \n",
       "3                                      None   \n",
       "4                                      None   \n",
       "5                                      None   \n",
       "6                                      None   \n",
       "7                               Houston, TX   \n",
       "8                               Houston, TX   \n",
       "9                               Houston, TX   \n",
       "10                            Rosenberg, TX   \n",
       "11                        Houston, TX 77090   \n",
       "12                           Sugar Land, TX   \n",
       "13        Houston, TX 77002 (Downtown area)   \n",
       "14  Kingwood, TX 77345 (Far Northeast area)   \n",
       "15                               Spring, TX   \n",
       "16                              Houston, TX   \n",
       "17                                     None   \n",
       "18                                     None   \n",
       "\n",
       "                               company  \\\n",
       "0                                 TTEC   \n",
       "1    Commercial Beverage Concepts, LLC   \n",
       "2                                 EMPC   \n",
       "3                             Allstyle   \n",
       "4                      GEORGIA-PACIFIC   \n",
       "5         Houston Gateway Academy, Inc   \n",
       "6                            Altus ACE   \n",
       "7                                  HEB   \n",
       "8                                  HEB   \n",
       "9                                  HEB   \n",
       "10             Frito-Lay North America   \n",
       "11                NINJA Nation - Aflac   \n",
       "12                                 HEB   \n",
       "13                       Harris County   \n",
       "14                                 HEB   \n",
       "15                                 HEB   \n",
       "16             Moderno Porcelain Works   \n",
       "17  U.S. Customs and Border Protection   \n",
       "18     Federal Bureau of Investigation   \n",
       "\n",
       "                                                title  star  \n",
       "0    Customer Service Representative - Work from Home   3.5  \n",
       "1                         Warehouse Financial Analyst  None  \n",
       "2                          Quality Control Specialist  None  \n",
       "3                 Global Shop ERP Software Specialist  None  \n",
       "4                                     PLYWOOD TRAINEE   3.4  \n",
       "5                      2020 - 2021 Certified Teachers  None  \n",
       "6                                 IT Business Analyst   2.3  \n",
       "7                           Curbside In Store Shopper   4.3  \n",
       "8                                             Checker   4.3  \n",
       "9                                 FT Curbside Shopper   4.3  \n",
       "10                         Warehouse/Material Handler   3.4  \n",
       "11  Insurance Agent - Training Provided & Flexible...  None  \n",
       "12                                      Night Stocker   4.3  \n",
       "13  Harris County Sheriff's Office Career Opportun...   3.7  \n",
       "14                                 Night Stocker - PT   4.3  \n",
       "15                              Grocery Night Stocker   4.3  \n",
       "16                           Apprentice - Houston, TX  None  \n",
       "17                                Border Patrol Agent   4.1  \n",
       "18                                      Special Agent   4.3  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

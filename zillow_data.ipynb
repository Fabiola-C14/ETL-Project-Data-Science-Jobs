{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "os.chdir(\"stfiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL for Zillow Ny housing data\n",
    "url = 'https://www.zillow.com/homes/New-York,-NY_rb/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape address, and listing price from Zillow NY\n",
    "\n",
    "#Scrape through multiple pages (note: On the first instance zillow allowed multiple extracts, after the first attempt I was only able to scrape 40 properties)\n",
    "for x in range(1,4):\n",
    "\n",
    "    nyresults= soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in nyresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "    \n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "\n",
    "        #print(f\" Address: {location}, Asking Price: {price}\")\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set dataframe\n",
    "ny_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "#ny_listing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asking Price</th>\n",
       "      <th>Street</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$350,000</td>\n",
       "      <td>17-44 166th St</td>\n",
       "      <td>Whitestone</td>\n",
       "      <td>NY 11357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$324,900</td>\n",
       "      <td>448 Neptune Ave APT 18A</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY 11224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$380,000</td>\n",
       "      <td>637 41st St APT 2D</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY 11232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$340,000</td>\n",
       "      <td>21-68 35th St #3F</td>\n",
       "      <td>Astoria</td>\n",
       "      <td>NY 11105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$1,799,000</td>\n",
       "      <td>18-13 26th Ave #1</td>\n",
       "      <td>Astoria</td>\n",
       "      <td>NY 11102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>$210,000</td>\n",
       "      <td>255 Fieldston Ter APT 4E</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NY 10471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$228,000</td>\n",
       "      <td>19958 21st Ave #1-166</td>\n",
       "      <td>Whitestone</td>\n",
       "      <td>NY 11357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>$388,000</td>\n",
       "      <td>9952 66th Rd APT 9D</td>\n",
       "      <td>Rego Park</td>\n",
       "      <td>NY 11374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$449,000</td>\n",
       "      <td>3165 Emmons Ave APT 1E</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY 11235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>$669,000</td>\n",
       "      <td>1973 E 33rd St</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY 11234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>$1,750,000</td>\n",
       "      <td>129 Tiffany Pl #A</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY 11231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>$1,499,000</td>\n",
       "      <td>433 Beach 143 St</td>\n",
       "      <td>Rockaway Park</td>\n",
       "      <td>NY 11694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>$695,000</td>\n",
       "      <td>249 Eldridge St APT 19</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY 10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>$725,000</td>\n",
       "      <td>314 W 19th St APT 4A</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY 10011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>$450,000</td>\n",
       "      <td>14 Orchard St APT 4G</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY 10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>$276,400</td>\n",
       "      <td>70 Selvin Loop #1</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>NY 10303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>$765,000</td>\n",
       "      <td>3425 Olinville Ave</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NY 10467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>$665,850</td>\n",
       "      <td>8081 88th Ave</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>NY 11421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>$849,850</td>\n",
       "      <td>1181 E 84th St</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY 11236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>$899,900</td>\n",
       "      <td>104-09 Martense Ave</td>\n",
       "      <td>Corona</td>\n",
       "      <td>NY 11368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>$1,200,000</td>\n",
       "      <td>246-11 52nd Ave</td>\n",
       "      <td>Little Neck</td>\n",
       "      <td>NY 11362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>$665,000</td>\n",
       "      <td>1912 Avenue H #4H</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY 11230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>$1,625,000</td>\n",
       "      <td>120 E 75th St #7A</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY 10021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>$875,000</td>\n",
       "      <td>305 E 24th St APT 11B</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY 10010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>$300,000</td>\n",
       "      <td>54-17 31st Ave #A2O</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>NY 11377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>$563,500</td>\n",
       "      <td>3424 Tiemann Ave</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NY 10469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>$448,500</td>\n",
       "      <td>2666 Briggs Ave</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NY 10458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>$4,370,000</td>\n",
       "      <td>25 Central Park W APT 16I</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY 10023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>$435,000</td>\n",
       "      <td>210 E 21st St APT 4D</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY 10010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>$415,000</td>\n",
       "      <td>61-35 98th St #7H</td>\n",
       "      <td>Rego Park</td>\n",
       "      <td>NY 11374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>$829,000</td>\n",
       "      <td>2 Tudor City Pl APT 4JS</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY 10017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>$2,550,000</td>\n",
       "      <td>200 Chambers St APT 16B</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY 10007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>$569,000</td>\n",
       "      <td>12202 Linden Blvd</td>\n",
       "      <td>South Ozone Park</td>\n",
       "      <td>NY 11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>$584,200</td>\n",
       "      <td>10242 188th St</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>NY 11423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>$572,700</td>\n",
       "      <td>16 W 11th Rd</td>\n",
       "      <td>Broad Channel</td>\n",
       "      <td>NY 11693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>$517,500</td>\n",
       "      <td>74 Dubois Ave</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>NY 10310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>$429,000</td>\n",
       "      <td>103-06 Rockaway Beach Blvd #1A</td>\n",
       "      <td>Rockaway Park</td>\n",
       "      <td>NY 11694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>$330,000</td>\n",
       "      <td>29 Eleanor Pl</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>NY 10303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>$1,348,888</td>\n",
       "      <td>8770 25th Ave</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY 11214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>$836,000</td>\n",
       "      <td>182 Olympia Blvd</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>NY 10305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Asking Price                          Street               City      State\n",
       "0      $350,000                  17-44 166th St         Whitestone   NY 11357\n",
       "1      $324,900         448 Neptune Ave APT 18A           Brooklyn   NY 11224\n",
       "2      $380,000              637 41st St APT 2D           Brooklyn   NY 11232\n",
       "3      $340,000               21-68 35th St #3F            Astoria   NY 11105\n",
       "4    $1,799,000               18-13 26th Ave #1            Astoria   NY 11102\n",
       "5      $210,000        255 Fieldston Ter APT 4E              Bronx   NY 10471\n",
       "6      $228,000           19958 21st Ave #1-166         Whitestone   NY 11357\n",
       "7      $388,000             9952 66th Rd APT 9D          Rego Park   NY 11374\n",
       "8      $449,000          3165 Emmons Ave APT 1E           Brooklyn   NY 11235\n",
       "9      $669,000                  1973 E 33rd St           Brooklyn   NY 11234\n",
       "10   $1,750,000               129 Tiffany Pl #A           Brooklyn   NY 11231\n",
       "11   $1,499,000                433 Beach 143 St      Rockaway Park   NY 11694\n",
       "12     $695,000          249 Eldridge St APT 19           New York   NY 10002\n",
       "13     $725,000            314 W 19th St APT 4A           New York   NY 10011\n",
       "14     $450,000            14 Orchard St APT 4G           New York   NY 10002\n",
       "15     $276,400               70 Selvin Loop #1      Staten Island   NY 10303\n",
       "16     $765,000              3425 Olinville Ave              Bronx   NY 10467\n",
       "17     $665,850                   8081 88th Ave            Jamaica   NY 11421\n",
       "18     $849,850                  1181 E 84th St           Brooklyn   NY 11236\n",
       "19     $899,900             104-09 Martense Ave             Corona   NY 11368\n",
       "20   $1,200,000                 246-11 52nd Ave        Little Neck   NY 11362\n",
       "21     $665,000               1912 Avenue H #4H           Brooklyn   NY 11230\n",
       "22   $1,625,000               120 E 75th St #7A           New York   NY 10021\n",
       "23     $875,000           305 E 24th St APT 11B           New York   NY 10010\n",
       "24     $300,000             54-17 31st Ave #A2O           Woodside   NY 11377\n",
       "25     $563,500                3424 Tiemann Ave              Bronx   NY 10469\n",
       "26     $448,500                 2666 Briggs Ave              Bronx   NY 10458\n",
       "27   $4,370,000       25 Central Park W APT 16I           New York   NY 10023\n",
       "28     $435,000            210 E 21st St APT 4D           New York   NY 10010\n",
       "29     $415,000               61-35 98th St #7H          Rego Park   NY 11374\n",
       "30     $829,000         2 Tudor City Pl APT 4JS           New York   NY 10017\n",
       "31   $2,550,000         200 Chambers St APT 16B           New York   NY 10007\n",
       "32     $569,000               12202 Linden Blvd   South Ozone Park   NY 11420\n",
       "33     $584,200                  10242 188th St            Jamaica   NY 11423\n",
       "34     $572,700                    16 W 11th Rd      Broad Channel   NY 11693\n",
       "35     $517,500                   74 Dubois Ave      Staten Island   NY 10310\n",
       "36     $429,000  103-06 Rockaway Beach Blvd #1A      Rockaway Park   NY 11694\n",
       "37     $330,000                   29 Eleanor Pl      Staten Island   NY 10303\n",
       "38   $1,348,888                   8770 25th Ave           Brooklyn   NY 11214\n",
       "39     $836,000                182 Olympia Blvd      Staten Island   NY 10305"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the address column by \",\"\n",
    "\n",
    "# new data frame with split value columns \n",
    "nynew = ny_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "ny_listing_df[\"Street\"]= nynew[0] \n",
    "  \n",
    "# making separate city column from new data frame \n",
    "ny_listing_df[\"City\"]= nynew[1] \n",
    "\n",
    "ny_listing_df[\"State\"]=nynew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "ny_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "  \n",
    "# df display \n",
    "ny_listing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to extract\n",
    "ny_listing_df.to_csv(\"ny_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Chicago data\n",
    "ch_url = 'https://www.zillow.com/homes/Chicago,-IL_rb/'\n",
    "browser.visit(ch_url)\n",
    "ch_html = browser.html\n",
    "ch_soup = BeautifulSoup(ch_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    chresults= ch_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in chresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create dataframe\n",
    "    ch_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "chnew = ch_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "ch_listing_df[\"Street\"]= chnew[0] \n",
    "# making separate city column from new data frame \n",
    "ch_listing_df[\"City\"]= chnew[1] \n",
    "# making separate city column from new data frame \n",
    "ch_listing_df[\"State\"]=chnew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "ch_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create CVS extract\n",
    "ch_listing_df.to_csv(\"ch_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow San Francisco data\n",
    "sf_url = 'https://www.zillow.com/homes/San-Francisco,-CA_rb/'\n",
    "browser.visit(sf_url)\n",
    "sf_html = browser.html\n",
    "sf_soup = BeautifulSoup(sf_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    sfresults= sf_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in sfresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create dataframe\n",
    "    sf_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "# new data frame with split value columns \n",
    "sfnew = sf_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "sf_listing_df[\"Street\"]= sfnew[0] \n",
    "# making separate city column from new data frame \n",
    "sf_listing_df[\"City\"]= sfnew[1] \n",
    "# making separate city column from new data frame \n",
    "sf_listing_df[\"State\"]=sfnew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "sf_listing_df.drop(columns =[\"Address\"], inplace = True)        \n",
    "\n",
    "#Create extract\n",
    "sf_listing_df.to_csv(\"sf_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Austin data\n",
    "au_url = 'https://www.zillow.com/homes/Austin,-TX_rb/'\n",
    "browser.visit(au_url)\n",
    "au_html = browser.html\n",
    "au_soup = BeautifulSoup(au_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    auresults= au_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in auresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create dataframe\n",
    "    au_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "# new data frame with split value columns \n",
    "aunew = au_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "au_listing_df[\"Street\"]= aunew[0] \n",
    "# making separate city column from new data frame \n",
    "au_listing_df[\"City\"]= aunew[1] \n",
    "# making separate city column from new data frame \n",
    "au_listing_df[\"State\"]=aunew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "au_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "au_listing_df.to_csv(\"au_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Seattle data\n",
    "se_url = 'https://www.zillow.com/homes/Seattle_rb/'\n",
    "browser.visit(se_url)\n",
    "se_html = browser.html\n",
    "se_soup = BeautifulSoup(se_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    seresults= se_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in seresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create dataframe\n",
    "    se_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "senew = se_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "se_listing_df[\"Street\"]= senew[0] \n",
    "# making separate city column from new data frame \n",
    "se_listing_df[\"City\"]= senew[1] \n",
    "# making separate city column from new data frame \n",
    "se_listing_df[\"State\"]=senew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "se_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "se_listing_df.to_csv(\"se_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Los Angeles data\n",
    "la_url = 'https://www.zillow.com/homes/Los-Angeles,-CA_rb/'\n",
    "browser.visit(la_url)\n",
    "la_html = browser.html\n",
    "la_soup = BeautifulSoup(la_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    laresults= la_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in laresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "\n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #create dataframe\n",
    "    la_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "lanew = la_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "la_listing_df[\"Street\"]= lanew[0] \n",
    "# making separate city column from new data frame \n",
    "la_listing_df[\"City\"]= lanew[1] \n",
    "# making separate city column from new data frame \n",
    "la_listing_df[\"State\"]=lanew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "la_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "la_listing_df.to_csv(\"la_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Philadelphia data\n",
    "pa_url = 'https://www.zillow.com/homes/Philadelphia,-PA_rb/'\n",
    "browser.visit(pa_url)\n",
    "pa_html = browser.html\n",
    "pa_soup = BeautifulSoup(pa_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    paresults= pa_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in paresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create dataframe\n",
    "    pa_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "panew = pa_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "pa_listing_df[\"Street\"]= panew[0] \n",
    "# making separate city column from new data frame \n",
    "pa_listing_df[\"City\"]= panew[1] \n",
    "# making separate city column from new data frame \n",
    "pa_listing_df[\"State\"]=panew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "pa_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "pa_listing_df.to_csv(\"pa_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Atlanta data\n",
    "at_url = 'https://www.zillow.com/homes/Atlanta,-GA_rb/'\n",
    "browser.visit(at_url)\n",
    "at_html = browser.html\n",
    "at_soup = BeautifulSoup(at_html, 'html5lib')\n",
    "#print(soup.prettify())\n",
    "for x in range(1,4):\n",
    "\n",
    "    atresults= at_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in atresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    at_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "atnew = at_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "at_listing_df[\"Street\"]= atnew[0] \n",
    "# making separate city column from new data frame \n",
    "at_listing_df[\"City\"]= atnew[1] \n",
    "# making separate city column from new data frame \n",
    "at_listing_df[\"State\"]=atnew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "at_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "at_listing_df.to_csv(\"at_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Dallas data\n",
    "da_url = 'https://www.zillow.com/homes/Dallas,-TX_rb/'\n",
    "browser.visit(da_url)\n",
    "da_html = browser.html\n",
    "da_soup = BeautifulSoup(da_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    daresults= da_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in daresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create dataframe\n",
    "    da_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "danew = da_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "da_listing_df[\"Street\"]= danew[0] \n",
    "# making separate city column from new data frame \n",
    "da_listing_df[\"City\"]= danew[1] \n",
    "# making separate city column from new data frame \n",
    "da_listing_df[\"State\"]=danew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "da_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "da_listing_df.to_csv(\"da_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Pittsburgh data\n",
    "pit_url = 'https://www.zillow.com/homes/Pittsburgh,-PA_rb/'\n",
    "browser.visit(pit_url)\n",
    "pit_html = browser.html\n",
    "pit_soup = BeautifulSoup(pit_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    pitresults= pit_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in pitresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "    \n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "\n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create extract\n",
    "    pit_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "pitnew = pit_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "pit_listing_df[\"Street\"]= pitnew[0]\n",
    "# making separate city column from new data frame \n",
    "pit_listing_df[\"City\"]= pitnew[1] \n",
    "# making separate city column from new data frame \n",
    "pit_listing_df[\"State\"]=pitnew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "pit_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "pit_listing_df.to_csv(\"pit_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Portland data\n",
    "por_url = 'https://www.zillow.com/homes/Portland,-OR_rb/'\n",
    "browser.visit(por_url)\n",
    "por_html = browser.html\n",
    "por_soup = BeautifulSoup(por_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    porresults= por_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in porresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "\n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create dataframe\n",
    "    por_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "pornew = por_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "por_listing_df[\"Street\"]= pornew[0] \n",
    "# making separate city column from new data frame \n",
    "por_listing_df[\"City\"]= pornew[1] \n",
    "# making separate city column from new data frame \n",
    "por_listing_df[\"State\"]=pornew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "por_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "por_listing_df.to_csv(\"por_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Phoenix data\n",
    "ph_url = 'https://www.zillow.com/homes/Phoenix,-AZ_rb/'\n",
    "browser.visit(ph_url)\n",
    "ph_html = browser.html\n",
    "ph_soup = BeautifulSoup(ph_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    phresults= ph_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in phresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create extract\n",
    "    ph_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "phnew = ph_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "ph_listing_df[\"Street\"]= phnew[0] \n",
    "# making separate city column from new data frame \n",
    "ph_listing_df[\"City\"]= phnew[1] \n",
    "# making separate city column from new data frame \n",
    "ph_listing_df[\"State\"]=phnew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "ph_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "ph_listing_df.to_csv(\"ph_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Denver data\n",
    "de_url = 'https://www.zillow.com/homes/Denver,-CO_rb/'\n",
    "browser.visit(de_url)\n",
    "de_html = browser.html\n",
    "de_soup = BeautifulSoup(de_html, 'html5lib')\n",
    "#print(soup.prettify())\n",
    "for x in range(1,4):\n",
    "\n",
    "    deresults= de_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in deresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "        \n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create extract\n",
    "    de_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "denew = de_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "de_listing_df[\"Street\"]= denew[0] \n",
    "# making separate city column from new data frame \n",
    "de_listing_df[\"City\"]= denew[1] \n",
    "# making separate city column from new data frame \n",
    "de_listing_df[\"State\"]=denew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "de_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "de_listing_df.to_csv(\"de_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Houston data\n",
    "ho_url = 'https://www.zillow.com/homes/Houston,-TX_rb/'\n",
    "browser.visit(ho_url)\n",
    "ho_html = browser.html\n",
    "ho_soup = BeautifulSoup(ho_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    horesults= ho_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in horesults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create dataframe\n",
    "    ho_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "honew = ho_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "ho_listing_df[\"Street\"]= honew[0] \n",
    "  \n",
    "# making separate city column from new data frame \n",
    "ho_listing_df[\"City\"]= honew[1] \n",
    "# making separate city column from new data frame \n",
    "ho_listing_df[\"State\"]=honew[2] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "ho_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Create extract\n",
    "ho_listing_df.to_csv(\"ho_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Zillow Miami data\n",
    "mi_url = 'https://www.zillow.com/homes/Miami,-FL_rb/'\n",
    "browser.visit(mi_url)\n",
    "mi_html = browser.html\n",
    "mi_soup = BeautifulSoup(mi_html, 'html5lib')\n",
    "\n",
    "for x in range(1,4):\n",
    "\n",
    "    miresults= mi_soup.find_all('div', class_='list-card-info')\n",
    "\n",
    "    address= []\n",
    "    asking_price=[]\n",
    "    for result in miresults: \n",
    "   \n",
    "        location = result.find('address', class_='list-card-addr').text\n",
    "        price = result.find('div', class_='list-card-price').text\n",
    "\n",
    "        address.append(location)\n",
    "        asking_price.append(price)\n",
    "    \n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    \n",
    "    #Create dataframe\n",
    "    mi_listing_df=pd.DataFrame ({\"Address\":address, \"Asking Price\": asking_price})\n",
    "\n",
    "\n",
    "# new data frame with split value columns \n",
    "minew = mi_listing_df[\"Address\"].str.split(\",\", n = 2, expand = True) \n",
    "  \n",
    "# making separate street column from new data frame \n",
    "mi_listing_df[\"Street\"]= minew[0] \n",
    "# making separate city column from new data frame \n",
    "mi_listing_df[\"City\"]= minew[1] \n",
    "# making separate city column from new data frame \n",
    "mi_listing_df[\"State\"]=minew[2] \n",
    "# Dropping old Name columns \n",
    "mi_listing_df.drop(columns =[\"Address\"], inplace = True) \n",
    "\n",
    "#Save into an extract\n",
    "mi_listing_df.to_csv(\"mi_data.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all extracts into a single file\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
